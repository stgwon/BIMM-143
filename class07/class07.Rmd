---
title: "Class 07: Machine Learning 1 & PCA Lab"
author: "Seong Tae Gwon"
date: "2/14/2022"
output:
  pdf_document: default
  html_document: default
---

# Part 1. Machine Learning 1 (Following the Tuesday's lab review video)

## First up kmeans(): Demo using kmeans() fucntion in base R

First make up some data with a known structure.
```{r}
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <- cbind(x=tmp, y=rev(tmp))
x
plot(x)
```

Now we have some made up data in `x`. Let's see how kmeans works with this data.
```{r}
k <- kmeans(x, centers=2, nstart=20)
k
```

> Q. How many points are in each cluster?

#### Answer:
```{r}
k$size
```
 > Q. How we do get to the clustr membership/assignment?

#### Answer:
```{r}
k$cluster
```

 > Q. What about cluster centers?

#### Answer:
```{r}
k$centers
```

Now, we got to the main results. Let's use them to plot our data with the kmeans 

```{r}
plot(x, col=k$cluster)
points(k$centers, col="blue", pch=15, cex=2)
```
## Now for Hierarchical Clustering

We will cluster the same data `x` with the `hclust()`. In this case, `hclust()` requires a dsitance matrix as input.

```{r}
hc <- hclust(dist(x))
hc
```

Let's plot our hclust result.

```{r}
plot(hc)
```

To get our cluster membership vector, we need to "cut" the tree with the `cutree()`.

```{r}
grps <- cutree(hc, h=8)
grps
```

Now, plot our data with the hclust() results.

```{r}
plot(x, col=grps)
```

# Part 2. Hands on with Principal Component Analysis (PCA)

## 1. PCA of UK food data

### Data import

Read the provided UK_foods.csv input file.

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

> Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

#### Answer:
```{r}
nrow(x)
ncol(x)
```

### Checking your data

Use the `View()` function to display all the data, or the `head()` and `tail()` functions to print only a portion of the data (by default 6 rows from either the top or bottom of the data set respectively).

```{r}
#View(x)
head(x)
```

Hmm, it looks like the row-names here were not set properly as we were expecting 4 columns (one for each of the 4 countries of the UK - not 5 as reported from the dim() function). Fix this up with 2 following methods.

One method: set the rownames() to the first column and then remove the troublesome first column (with the -1 column index).
```{r}
# Note how the minus indexing works
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
dim(x)
```

Second method: set the row.names argument of read.csv() to be the first column
```{r}
x <- read.csv(url, row.names=1)
head(x)
dim(x)
```

> Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

#### Answer:
I prefer the second approach because the first approach deletes a column of the data set every time I run the code. 

### Spotting major differnces and trends

Quick glance of the data set with a regular bar plot.
```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q3. Changing what optional argument in the above barplot() function results in the following plot?

#### Answer:
```{r}
# Setting beside=F in the previous barplot() code
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

> Q5. Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

```{r}
pairs(x, col=rainbow(10), pch=16)
```

#### Answer:
Each row represents a pairwise comparison between the labeled country (y-axis) and the corresponding country in each column (x-axis). For example, the second plot in the first row is a comparison between England and Wales. 17 different colors in each plot represent each value (food) of the column (country). The diagonal in each plot represents how similar x and y values are. If a given point doesn't lie on the diagonal, two countries have a difference in food data (lower the diagonal = y country has more, above the diagonal = x country has more). 

> Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

#### Answer:
N. Ireland's food data differs from the other countries since points in every plot don't lie on the diagonal.  

### PCA to the rescue

To perform PCA, we will use the base R `prcomp()` function.
`prcomp()` expects the *observations* as rows and the *variables* as columns.
First, we want to transpose our data.frame matrix with the `t()` transpose function.

```{r}
# Use the prcomp() PCA function 
pca <- prcomp( t(x) )
summary(pca)
```

```{r}
# Look inside the PCA object
attributes(pca)
```

> Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

#### Answer:
```{r}
# To make our new PCA plot (a.k.a. PCA score plot), we access `pca$x`
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
# Add column names to the plot
text(pca$x[,1], pca$x[,2], colnames(x))
```

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

#### Answer:
```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
color <- c("orange", "red", "blue", "green")
text(pca$x[,1], pca$x[,2], colnames(x), col=color)
```

Once the principal components have been obtained, we can use them to map the relationship between variables (i.e. countries) in therms of these major PCs (i.e. new axis that maximally describe the original data variance).

Below we can use the square of pca$sdev , which stands for “standard deviation”, to calculate how much variation in the original data each PC accounts for.
```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
## or the second row here...
z <- summary(pca)
z$importance
```

This information can be summarized in a plot of the variances (eigenvalues) with respect to the principal component number (eigenvector number).
```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

### Digging deeper (variable loadings)

We can also consider the influence of each of the original variables upon the principal components (typically known as loading scores). This information can be obtained from the prcomp() returned $rotation component. It can also be summarized with a call to biplot().
```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```
> Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

#### Answer:
```{r}
par(mar=c(10, 3, 0.35, 0))
barplot(pca$rotation[,2], las=2)
```
Two food groups that feature prominently are `Fresh_potatoes` and `Soft_drinks`.
PC2 mainly tells us that there is lower variance in the other food groups. This is illustrated by the similar distributions and loading scores closer to 0.

### Biplots

Another way to see this information together with the main PCA plot.
```{r}
# The inbuild biplot() can be useful for small datasets
biplot(pca)
```
Two food groups `Fresh_potatoes` and `Soft_drinks` feature prominently here.

## 2. PCA of RNA-seq data

Read a small RNA-seq count data set into a data frame called rna.data where the columns are individual samples (i.e. cells) and rows are measurements taken for all the samples (i.e. genes).
```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

> Q10: How many genes and samples are in this data set?

```{r}
# Samples
nrow(x)
# Genes
ncol(x)
```

#### Answer:
There are 17 samples and 4 genes in this data set.

Generating barplots etc. to make sense of this data is really not an exciting or worthwhile option to consider. So lets do PCA and plot the results.

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)
 
## Simple un polished plot of pc1 and pc2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

Examine a summary of how much variation in the original data each PC accounts for.
```{r}
summary(pca)
```

**Based on these results, PC1 is where all the action is (accounts for 92.6% of the variations) **

A quick barplot summary of this Proportion of Variance for each PC can be obtained by calling the plot() function directly on our prcomp result object.
```{r}
plot(pca, main="Quick scree plot")
```

We can use the square of `pra$sdev` to calculate how much variation in the original data each PC accounts for.
```{r}
## Variance captured per PC 
pca.var <- pca$sdev^2

## Percent variance is often more informative to look at 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

Generate a screen plot.
```{r}
barplot(pca.var.per, main="Scree Plot", 
        names.arg = paste0("PC", 1:10),
        xlab="Principal Component", ylab="Percent Variation")
```

**Based on this plot, PC1 is where all the action is **

Now lets make our main PCA plot a bit more attractive and useful.
```{r}
## A vector of colors for wt and ko samples
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)"))

text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))
```

# Using ggplot

We need a data.frame as input for the main ggplot() function. This data.frame will need to contain our PCA results (specifically pca$x) and additional columns for any other aesthetic mappings we will want to display. 
```{r}
library(ggplot2)

df <- as.data.frame(pca$x)

# Our first basic plot
ggplot(df) + 
  aes(PC1, PC2) + 
  geom_point()
```

Add a condition-specific color and label aesthetics for wild-type and knock-out samples.
```{r}
# Add a 'wt' and 'ko' "condition" column
df$samples <- colnames(rna.data) 
df$condition <- substr(colnames(rna.data),1,2)

p <- ggplot(df) + 
        aes(PC1, PC2, label=samples, col=condition) + 
        geom_label(show.legend = FALSE)
p
```

Finally add some spit and polish.
```{r}
p + labs(title="PCA of RNASeq Data",
       subtitle = "PC1 clealy seperates wild-type from knock-out samples",
       x=paste0("PC1 (", pca.var.per[1], "%)"),
       y=paste0("PC2 (", pca.var.per[2], "%)"),
       caption="BIMM143 example data") +
     theme_bw()
```

# Optional: Gene loadings

let’s find the top 10 measurements (genes) that contribute most to pc1 in either direction (+ or -).
```{r}
loading_scores <- pca$rotation[,1]

## Find the top 10 measurements (genes) that contribute
## most to PC1 in either direction (+ or -)
gene_scores <- abs(loading_scores) 
gene_score_ranked <- sort(gene_scores, decreasing=TRUE)

## show the names of the top 10 genes
top_10_genes <- names(gene_score_ranked[1:10])
top_10_genes 
```

These may be the genes that we would like to focus on for further analysis (if their expression changes are significant - we will deal with this and further steps of RNA-Seq analysis in subsequent classes).